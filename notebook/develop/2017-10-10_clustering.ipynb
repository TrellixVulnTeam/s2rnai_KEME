{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering of transcripts upstream of TSS\n",
    "\n",
    "Work on clustering transcripts using their conservation score 1 kb upstream of TSS:\n",
    "- slice\n",
    "- intersect w/conservation scores\n",
    "- 10 bp bins\n",
    "- avg score w/in bins\n",
    "- table\n",
    "- standardize\n",
    "- cluster! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/bergeric/miniconda3/envs/s2rnai/lib/python3.5/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import gffutils\n",
    "from gffutils import pybedtools_integration\n",
    "import pybedtools\n",
    "from pybedtools.featurefuncs import gff2bed\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import database and define transcripts, genes, tsses, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/bergeric/miniconda3/envs/s2rnai/lib/python3.5/site-packages/gffutils/interface.py:161: UserWarning: It appears that this database has not had the ANALYZE sqlite3 command run on it. Doing so can dramatically speed up queries, and is done by default for databases created with gffutils >0.8.7.1 (this database was created with version 0.8.7.1) Consider calling the analyze() method of this object.\n",
      "  \"method of this object.\" % self.version)\n"
     ]
    }
   ],
   "source": [
    "db = gffutils.FeatureDB('/data/LCDB/lcdb-references/dmel/r6-11/gtf/dmel_r6-11.gtf.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transcripts = pybedtools_integration.to_bedtool(db.features_of_type('transcript')).saveas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genes = pybedtools_integration.to_bedtool(db.features_of_type('gene')).sort().merge().saveas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tss = pybedtools_integration.tsses(db, merge_overlapping=False).saveas('../../output/tsses.gff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slop = tss.slop(l=1000, r=0, s=True, genome='dm6').saveas('../../output/another_slop.bed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Get intersections TSS w/exons, TSS w/introns, TSS w/intergenic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TSS_exons = tss.intersect('../../output/dm6_exons.bed').saveas().to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "introns = pd.read_table('../../output/dmel-introns-r6.11.gff', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "introns[0] = [ 'chr'+x for x in introns[0] ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tss_introns = tss.intersect(pybedtools.BedTool.from_dataframe(introns), wa=True).saveas().to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TSS_intergenic = tss.intersect('../../output/intergenic.bed').saveas().to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Intersect upstream of TSS w/conservation scores:\n",
    "\n",
    "(If I try to do here will fail, probably because I don't have enough memory? so doing it on local machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#wig2bed < dm6.27way.phastCons.wigFix > dm6_phastcons.bed\n",
    "phastcons = pybedtools.BedTool('../../output/dm6_phastcons.bed').saveas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import intersect file: (really big, splitting by chrom)\n",
    "intersect_2L = pd.read_table('../../output/2L_intersect', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "want to break up into 10 bp bins, with average conservation score. In order to do that, \n",
    "### iterate by TSS:  \n",
    "\n",
    "- read in another slop line by line\n",
    "- for each line, make windows, then intersect with phastcons, then take that and agg over scores\n",
    "- intersect back with another_slop to get gene/transcript info? or could take that out in parser maybe? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsses = pd.read_table('../../output/another_slop.bed', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsses_2L = tsses[tsses[0] == 'chr2L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/bergeric/miniconda3/envs/s2rnai/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "tsses_2L[8] = [ x.split()[3].strip(';').strip('\"') for x in list(tsses_2L[8]) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsses_2L = tsses_2L.groupby([0,3,4])[8].apply(lambda x:'|'.join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>6529</td>\n",
       "      <td>7529</td>\n",
       "      <td>FBtr0300689|FBtr0300690|FBtr0330654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>18570</td>\n",
       "      <td>19570</td>\n",
       "      <td>FBtr0078170|FBtr0078171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>20952</td>\n",
       "      <td>21952</td>\n",
       "      <td>FBtr0309810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>21376</td>\n",
       "      <td>22376</td>\n",
       "      <td>FBtr0078168|FBtr0078166|FBtr0078167|FBtr007816...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr2L</td>\n",
       "      <td>25155</td>\n",
       "      <td>26155</td>\n",
       "      <td>FBtr0113008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      3      4                                                  8\n",
       "0  chr2L   6529   7529                FBtr0300689|FBtr0300690|FBtr0330654\n",
       "1  chr2L  18570  19570                            FBtr0078170|FBtr0078171\n",
       "2  chr2L  20952  21952                                        FBtr0309810\n",
       "3  chr2L  21376  22376  FBtr0078168|FBtr0078166|FBtr0078167|FBtr007816...\n",
       "4  chr2L  25155  26155                                        FBtr0113008"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsses_2L.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phastcons = pybedtools.BedTool('../../output/2L_phastcons.bed').saveas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "done_yesterday = pd.read_table('../../output/done_from_yesterday', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "done_yesterday = done_yesterday.drop(done_yesterday.index[3822])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((6529, 7529),        0     3     4                                    8\n",
      "0  chr2L  6529  7529  FBtr0300689|FBtr0300690|FBtr0330654)\n"
     ]
    }
   ],
   "source": [
    "for val in done_yesterday[0].tolist():\n",
    "    print(val)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((6529, 7529),        0     3     4                                    8\n",
      "0  chr2L  6529  7529  FBtr0300689|FBtr0300690|FBtr0330654)\n"
     ]
    }
   ],
   "source": [
    "for name, group in tsses_2L.groupby([3,4]):\n",
    "    if ((name,group)) not in done_yesterday[0].tolist():\n",
    "        print((name,group))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bins(chrom,a,b,n):\n",
    "    bins = pd.cut([a,b], n, retbins=True, include_lowest=True)[1]\n",
    "    collect = []\n",
    "    for i in range(n):\n",
    "        collect.append([chrom, int(list(bins)[i:i+2][0]), int(list(bins)[i:i+2][1])])\n",
    "    return collect\n",
    "\n",
    "done=[]\n",
    "errors=[]\n",
    "for name, group in tsses_2L.groupby([3,4]):\n",
    "    if (name, group) not in done:\n",
    "        concat=[]\n",
    "        done.append([name, group])\n",
    "        bins = make_bins(list(group[0])[0], name[0], name[1], 100)\n",
    "        df = pd.DataFrame(bins)\n",
    "        intersect = pybedtools.BedTool.from_dataframe(df).intersect(phastcons, wo=True)\n",
    "        try:\n",
    "            intersect = intersect.to_dataframe()\n",
    "            agg = intersect.groupby(['chrom', 'start', 'end']).agg({'thickEnd':'mean'}).reset_index()\n",
    "            with_name = agg.copy()\n",
    "            with_name['name'] = list(group[8])[0]\n",
    "            concat.append(with_name)\n",
    "            final = pd.concat(concat)\n",
    "            final = final[['chrom','start','end','name','thickEnd']]\n",
    "            final.to_csv('../../output/tss_windows_wphastcons_3', sep='\\t', header=None, index=False, mode='a')\n",
    "        except: \n",
    "            errors.append(name)\n",
    "        pd.DataFrame(done).to_csv('../../output/done_from_today', header=None, index=False, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Stop running and save done so that I can keep going with it on a new compute node tomorrow?? \n",
    "pd.Series(done).to_csv('../../output/done_from_yesterday', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:s2rnai]",
   "language": "python",
   "name": "conda-env-s2rnai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
